{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c01961d",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-05-24T15:27:41.300984Z",
     "iopub.status.busy": "2024-05-24T15:27:41.300503Z",
     "iopub.status.idle": "2024-05-24T15:27:48.724346Z",
     "shell.execute_reply": "2024-05-24T15:27:48.723368Z"
    },
    "papermill": {
     "duration": 7.434431,
     "end_time": "2024-05-24T15:27:48.727221",
     "exception": false,
     "start_time": "2024-05-24T15:27:41.292790",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "#for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#    for filename in filenames:\n",
    "#        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a763df60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-24T15:27:48.741280Z",
     "iopub.status.busy": "2024-05-24T15:27:48.739694Z",
     "iopub.status.idle": "2024-05-24T15:27:48.751209Z",
     "shell.execute_reply": "2024-05-24T15:27:48.750208Z"
    },
    "papermill": {
     "duration": 0.02068,
     "end_time": "2024-05-24T15:27:48.753733",
     "exception": false,
     "start_time": "2024-05-24T15:27:48.733053",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the ResNet architecture\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(residual)\n",
    "        out = F.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fab0879",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-24T15:27:48.766502Z",
     "iopub.status.busy": "2024-05-24T15:27:48.765725Z",
     "iopub.status.idle": "2024-05-24T15:27:48.778914Z",
     "shell.execute_reply": "2024-05-24T15:27:48.777787Z"
    },
    "papermill": {
     "duration": 0.022252,
     "end_time": "2024-05-24T15:27:48.781392",
     "exception": false,
     "start_time": "2024-05-24T15:27:48.759140",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, num_classes=14):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 16\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.layer1 = self.make_layer(ResidualBlock, 16, 2, stride=1)\n",
    "        self.layer2 = self.make_layer(ResidualBlock, 32, 2, stride=2)\n",
    "        self.layer3 = self.make_layer(ResidualBlock, 64, 2, stride=2)\n",
    "        self.dropout = nn.Dropout(0.5)  # Dropout added for regularization\n",
    "        self.fc = None # Initialize fc layer as None\n",
    "\n",
    "    def make_layer(self, block, out_channels, blocks, stride=1):\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, stride))\n",
    "        self.in_channels = out_channels\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(out_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = F.avg_pool2d(out, 8)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.dropout(out)\n",
    "        if self.fc is None:\n",
    "            self.fc = nn.Linear(out.size(1), 14)  # Initialize fc layer with correct input features\n",
    "        out =self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b17900f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-24T15:27:48.793928Z",
     "iopub.status.busy": "2024-05-24T15:27:48.793514Z",
     "iopub.status.idle": "2024-05-24T15:27:48.803625Z",
     "shell.execute_reply": "2024-05-24T15:27:48.802643Z"
    },
    "papermill": {
     "duration": 0.01935,
     "end_time": "2024-05-24T15:27:48.806131",
     "exception": false,
     "start_time": "2024-05-24T15:27:48.786781",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the GCN part with additional normalization (unchanged)\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_features: int, out_features: int):\n",
    "        super(GCN, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(in_features, out_features))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "    def forward(self, input: torch.Tensor, adj: torch.Tensor, deg: torch.Tensor):\n",
    "        epsilon = 1e-9\n",
    "        input = input.matmul(self.weight)\n",
    "        deg = torch.diag(deg.sum(dim=1)) + epsilon\n",
    "        deg_inv_sqrt = torch.pow(deg, 0.5)\n",
    "        deg_inv_sqrt[torch.isinf(deg_inv_sqrt)] = 0\n",
    "        output = deg_inv_sqrt.matmul(adj).matmul(deg_inv_sqrt).matmul(input.transpose(0, 1))\n",
    "        output = output.transpose(0, 1)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "187413bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-24T15:27:48.820536Z",
     "iopub.status.busy": "2024-05-24T15:27:48.819046Z",
     "iopub.status.idle": "2024-05-24T15:27:48.830596Z",
     "shell.execute_reply": "2024-05-24T15:27:48.829213Z"
    },
    "papermill": {
     "duration": 0.021953,
     "end_time": "2024-05-24T15:27:48.833546",
     "exception": false,
     "start_time": "2024-05-24T15:27:48.811593",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GCNLayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(GCNLayer, self).__init__()\n",
    "        self.linear = nn.Linear(in_features, out_features)\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        x = self.linear(x)\n",
    "        x = torch.matmul(x, adj)  # Graph convolution operation\n",
    "#        x = F.relu(x)  # Activation function\n",
    "        return x\n",
    "    \n",
    "class GCN2(nn.Module):\n",
    "    def __init__(self, in_features, hidden_dim, out_features):\n",
    "        super(GCN2, self).__init__()\n",
    "        self.gcn1 = GCNLayer(in_features, hidden_dim)\n",
    "        self.gcn2 = GCNLayer(hidden_dim, out_features)\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        x = self.gcn1(x, adj)\n",
    "        x = self.gcn2(x, adj)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "831790f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-24T15:27:48.846807Z",
     "iopub.status.busy": "2024-05-24T15:27:48.846421Z",
     "iopub.status.idle": "2024-05-24T15:27:48.854169Z",
     "shell.execute_reply": "2024-05-24T15:27:48.852915Z"
    },
    "papermill": {
     "duration": 0.017112,
     "end_time": "2024-05-24T15:27:48.856687",
     "exception": false,
     "start_time": "2024-05-24T15:27:48.839575",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FedGNN(nn.Module):\n",
    "    def __init__(self, resnet: ResNet, gcn: GCN, gcn2:GCN2):\n",
    "        super(FedGNN, self).__init__()\n",
    "        self.resnet = resnet\n",
    "        self.gcn = gcn\n",
    "        self.gcn2 = gcn2\n",
    "\n",
    "    def forward(self, x: torch.Tensor, adj: torch.Tensor, deg: torch.Tensor):\n",
    "        x = self.resnet(x)\n",
    "        x = self.gcn(x, adj, deg)\n",
    "        x = self.gcn2(x,adj)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65032055",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-24T15:27:48.869377Z",
     "iopub.status.busy": "2024-05-24T15:27:48.868996Z",
     "iopub.status.idle": "2024-05-24T15:27:50.618951Z",
     "shell.execute_reply": "2024-05-24T15:27:50.617667Z"
    },
    "papermill": {
     "duration": 1.75928,
     "end_time": "2024-05-24T15:27:50.621498",
     "exception": false,
     "start_time": "2024-05-24T15:27:48.862218",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2735 1641 547 547\n"
     ]
    }
   ],
   "source": [
    "# Rest of the code remains the same\n",
    "def load_data_and_split(data_dir: str, transform: transforms.Compose, train_split=0.6, val_split=0.2):\n",
    "    dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "    total_size = len(dataset)\n",
    "    train_size = int(total_size * train_split)\n",
    "    val_size = int(total_size * val_split)\n",
    "    test_size = total_size - train_size - val_size\n",
    "    print(total_size,train_size,val_size,test_size)\n",
    "    train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "    return train_dataset, val_dataset, test_dataset\n",
    "\n",
    "# Transformations\n",
    "transformations = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load and split the data\n",
    "train_dataset, val_dataset, test_dataset = load_data_and_split('/kaggle/input/plant-dis/PLANT DISEASES/PD', transformations)\n",
    "\n",
    "# DataLoader setup\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "# Model, criterion, optimizer, and scheduler setup\n",
    "# Assume the ResNet's output shape is 14 (adjust this value if it's different)\n",
    "resnet = ResNet()\n",
    "gcn = GCN(in_features=14, out_features=14)\n",
    "gcn2 = GCN2(in_features=14, hidden_dim = 14,out_features=14)\n",
    "model = FedGNN(resnet,gcn, gcn2)\n",
    "#model = FedGNN(ResNet(), GCN(in_features=64, out_features=14))\n",
    "\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=0.001, weight_decay=0.001)\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=0.0001)  # Learning rate decay\n",
    "adj_matrix = torch.ones(14) - torch.eye(14) \n",
    "row_sums = adj_matrix.sum(dim=1)\n",
    "adj_matrix_normalized = adj_matrix / row_sums.unsqueeze(1) # Simplified adjacency matrix, replace with your actual adjacency matrix\n",
    "degree_matrix = torch.diag(adj_matrix.sum(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bed61ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-24T15:27:50.634366Z",
     "iopub.status.busy": "2024-05-24T15:27:50.633590Z",
     "iopub.status.idle": "2024-05-24T15:27:50.640210Z",
     "shell.execute_reply": "2024-05-24T15:27:50.638792Z"
    },
    "papermill": {
     "duration": 0.015657,
     "end_time": "2024-05-24T15:27:50.642644",
     "exception": false,
     "start_time": "2024-05-24T15:27:50.626987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n",
      "18\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader))\n",
    "print(len(val_loader))\n",
    "print(len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a409e067",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-24T15:27:50.656008Z",
     "iopub.status.busy": "2024-05-24T15:27:50.655055Z",
     "iopub.status.idle": "2024-05-24T15:27:50.661692Z",
     "shell.execute_reply": "2024-05-24T15:27:50.660630Z"
    },
    "papermill": {
     "duration": 0.016146,
     "end_time": "2024-05-24T15:27:50.664342",
     "exception": false,
     "start_time": "2024-05-24T15:27:50.648196",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FedGNN(\n",
      "  (resnet): ResNet(\n",
      "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (layer1): Sequential(\n",
      "      (0): ResidualBlock(\n",
      "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential()\n",
      "      )\n",
      "      (1): ResidualBlock(\n",
      "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): ResidualBlock(\n",
      "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential(\n",
      "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): ResidualBlock(\n",
      "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): ResidualBlock(\n",
      "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential(\n",
      "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): ResidualBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (gcn): GCN()\n",
      "  (gcn2): GCN2(\n",
      "    (gcn1): GCNLayer(\n",
      "      (linear): Linear(in_features=14, out_features=14, bias=True)\n",
      "    )\n",
      "    (gcn2): GCNLayer(\n",
      "      (linear): Linear(in_features=14, out_features=14, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42e3d927",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-24T15:27:50.677562Z",
     "iopub.status.busy": "2024-05-24T15:27:50.677144Z",
     "iopub.status.idle": "2024-05-24T15:27:50.689167Z",
     "shell.execute_reply": "2024-05-24T15:27:50.688092Z"
    },
    "papermill": {
     "duration": 0.021475,
     "end_time": "2024-05-24T15:27:50.691598",
     "exception": false,
     "start_time": "2024-05-24T15:27:50.670123",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training, validation, and testing functions\n",
    "def train_model(model, train_loader, criterion, optimizer, scheduler, num_epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for images, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images,adj_matrix, degree_matrix)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        scheduler.step()  # Step the scheduler at each epoch\n",
    "        print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n",
    "\n",
    "def validate_model(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            outputs = model(images,adj_matrix, degree_matrix)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "    average_loss = total_loss / len(val_loader)\n",
    "    print(f'Validation Loss: {average_loss}')\n",
    "\n",
    "def test_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            outputs = model(images,adj_matrix, degree_matrix)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(f'Accuracy of the model on the test images: {100 * correct / total}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0026dafc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-24T15:27:50.705050Z",
     "iopub.status.busy": "2024-05-24T15:27:50.704468Z",
     "iopub.status.idle": "2024-05-24T15:31:42.937467Z",
     "shell.execute_reply": "2024-05-24T15:31:42.936001Z"
    },
    "papermill": {
     "duration": 232.242652,
     "end_time": "2024-05-24T15:31:42.940042",
     "exception": false,
     "start_time": "2024-05-24T15:27:50.697390",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 6.028417587280273\n",
      "Epoch 2, Loss: 3.9241180419921875\n",
      "Epoch 3, Loss: 2.203598737716675\n",
      "Epoch 4, Loss: 3.6041746139526367\n",
      "Epoch 5, Loss: 3.8227932453155518\n",
      "Epoch 6, Loss: 4.061814308166504\n",
      "Epoch 7, Loss: 8.737133026123047\n",
      "Epoch 8, Loss: 2.2948732376098633\n",
      "Epoch 9, Loss: 3.559375286102295\n",
      "Epoch 10, Loss: 6.660406112670898\n",
      "Validation Loss: 2.186882926358117\n",
      "Accuracy of the model on the test images: 36.01462522851919%\n"
     ]
    }
   ],
   "source": [
    "# Execute the training, validation, and testing\n",
    "train_model(model, train_loader, criterion, optimizer, scheduler, num_epochs=10)\n",
    "validate_model(model, val_loader, criterion)\n",
    "test_model(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b667881",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-24T15:31:42.956181Z",
     "iopub.status.busy": "2024-05-24T15:31:42.955389Z",
     "iopub.status.idle": "2024-05-24T15:31:45.907358Z",
     "shell.execute_reply": "2024-05-24T15:31:45.906202Z"
    },
    "papermill": {
     "duration": 2.962994,
     "end_time": "2024-05-24T15:31:45.909948",
     "exception": false,
     "start_time": "2024-05-24T15:31:42.946954",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test images: 36.01462522851919%\n"
     ]
    }
   ],
   "source": [
    "test_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763586d1",
   "metadata": {
    "papermill": {
     "duration": 0.006496,
     "end_time": "2024-05-24T15:31:45.923407",
     "exception": false,
     "start_time": "2024-05-24T15:31:45.916911",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4853238,
     "sourceId": 8194146,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 248.999334,
   "end_time": "2024-05-24T15:31:47.355652",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-24T15:27:38.356318",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
